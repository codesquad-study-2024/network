# story 01 사내에 웹 서버를 설치하는 경우
## 1 사내에 웹 서버를 설치하는 경우
### 사내 LAN 에 공개용 서버를 직접 설치
요즘 이 방법을 사용하지 않는 이유
- IP 주소 부족 문제: LAN 에 연결된 클라이언트 PC 에 할당할 IP 주소가 부족
- 보안 문제: 
  - 서버에 도착한 패킷을 차단할 방법이 없음
  - 서버 보안을 높인다해도 설정에 대한 휴먼 에러로 취약점이 생길 수 있음

### 공개용 서버 앞단에 방화벽을 설치
일반화된 방법
- 특정 서버의 특정 애플리케이션에 액세스하는 패킷만 통과, 나머진 차단
- 애플리케이션에 보안 취약점이 있으면 방화벽이 있어도 무용지물

## 2 데이터센터에 웹 서버를 설치하는 경우
프로바이더 등이 운영하는 데이터센터 내 서버를 빌려쓰는 형태.  
고속 회선 덕분에 고속으로 액세스가 가능.  
데이터센터는 내진 설계, 자가 발전 장치 등 회사보다 안전한 경우가 많음.  
데이터센터에 방화벽이 설치된 경우 패킷 검사 후 서버에 도착.

---

# story 02 방화벽 원리와 동작
## 1 패킷 필터링형이 주류이다
방화벽 유형:
  - 패킷 필터링형: 성능, 가격, 사용 편의성면에서 사용하기 좋음 --> 가장 많이 사용
  - 애플리케이션 게이트웨이형
  - 서킷 게이트웨이형

## 2 패킷 필터링의 조건 설정 개념
패킷의 헤더엔 통신 제어 정보가 들어있는데, 패킷 필터링의 조건 설정에 자주 쓰이는 항목들이 있다.
- MAC 헤더:
  - 송신처 MAC 주소
- IP 헤더
  - 송신처 IP 주소
  - 수신처 IP 주소
  - 프로토콜 번호
  - 프래그먼트: 패킷 분할 시 해당 패킷이 두 번쨰 이후임을 판별할 때 사용
- TCP / UDP 헤더
  - 송신처 포트 번호: `서버`에서 반송할 때 사용. `클라이언트`의 포트 번호는 무작위 번호라서 사용하는 경우가 거의 없음.
  - 수신처 포트 번호: `서버의 포트 번호`를 사용하고 `클라이언트의 포트 번호`는 사용 X
  - TCP 컨트롤 비트: ACK, SYN, RST, PSH, FIN
- ICMP 메시지 내용(헤더가 아님): ICMP 메시지 유형
  - 0: `ICMP 에코 메시지`의 응답
  - 8: ping 명령어 실행 --> `ICMP 에코 메시지` 발송
  - 기타: 0 과 8 이외는 차단 시 네트워크 오류를 초래하므로 주의

### 조건 설정 예시
웹 서버에 대한 방화벽 설정. 클라이언트에 대한 설정을 하지 않음.
1. `수신처` IP 주소 + 포트 번호로 필터링: 웹 서버의 IP 주소와 포트 번호 80에 대해서만 허용
2. `송신처` IP 주소 + 포트 번호로 필터링: 
   - 송신처가 웹 서버 IP 주소 + 80 포트 번호 일 때 `SYN=1, ACK=0` 인 패킷은 차단: TCP handshake 첫 단계인 소켓 연결 시도를 차단
   - 그 외 송신처가 웹 서버 IP 주소 + 80 포트 번호인 패킷은 모두 허용
3. 1번과 2번 조건 외엔 모두 차단: 웹 서버가 아닌 사내 LAN 에 연결된 클라이언트 PC 에 대해선 인터넷 액세스를 모두 차단

## 3 애플리케이션을 한정할 때 포트 번호를 사용한다
웹 서버 이외의 애플리케이션에 대한 불필요한 패킷은 전부 차단하는 것이 좋다.  
--> 책에선 웹 서버의 포트 번호인 80 포트만 허용

## 4 컨트롤 비트로 접속 방향을 판단한다
TCP 연결 시 3-way handshake 동작을 한다. 이 때 TCP 헤더의 TCP 컨트롤 비트로 접속 방향을 판단할 수 있다.  
`SYN=1, ACK=0` 인 패킷을 차단하면 웹 서버에서 인터넷으로 액세스를 할 수 없도록 한다.  
이 방법은 UDP 동작에는 적용되지 않기 때문에 어느 정도 위험을 감수하고 연결하거나 불편을 감수하고 전부 차단한다.  

## 5 사내 LAN 에서 공개 서버용 LAN 으로 조건을 설정한다
- `사내 LAN - 인터넷`
- `사내 LAN - 공개 서버용 LAN`
위 두 가지 케이스에 대해 패킷을 허용하되, 설정을 잘못해서 `공개 서버용 LAN` 에 모든 패킷을 허용한다면 `공개 서버용 LAN`에 연결된 서버들이 모두 위험

## 6 밖에서 사내 LAN 으로 액세스할 수 없다
패킷 필터링형 방화벽은 `주소 변환 기능` 을 갖고있다.  
`프라이빗 주소 - 글로벌 주소` 또는 포트 번호 매핑은 자동으로 할 수 있기 때문에 패킷의 송신처와 수신처만 보고 `주소 변환이 필요한지`만 설정한다.

## 7 방화벽을 통과한다
- 방화벽에 도착한 패킷 중 차단할 패킷은 버리는데, 이떄 버린 패킷을 기록한다.
  - 만약 라우터가 방화벽 역할도 맡는다면, 라우터의 메모리 용량은 작기 때문에 기록하지 않는다.
- 방화벽을 통과한 패킷은 라우터가 중계하듯이 똑같이 중계된다.

## 8 방화벽으로 막을 수 없는 공격
방화벽은 패킷에 담긴 데이터를 검사하진 않는다.  
따라서 일단 통과한 패킷은 웹 서버에서 문제를 일으킬 수 있기 때문에 대처법이 필요하다.
- 대처법 1: 애플리케이션의 버그를 고친다
- 대처법 2: 패킷에 담긴 데이터를 조사하는 소프트웨어나 하드웨어를 준비한다.
- 하지만 이런 대처법들을 쓰더라도 미지의 위험(잠재적인 버그 등)은 막을 수 없다.
---
# story 03 복수 서버에 리퀘스트를 분배한 서버의 부하 분산
## 1 처리 능력이 부족하면 복수 서버로 부하 분산된다
서버의 처리 능력이 대량의 패킷을 감당하지 못할 때 두 가지 방법이 있다.
1. `수직적 확장`: 서버의 컴퓨팅 파워 향상 --> 서버 한 대의 처리 능력 향상
2. `수평적 확장`: 복수의 서버를 사용 (=`분산 처리`) --> 서버 한 대의 처리량을 감소

### 분산처리 방법: DNS 서버에서 분배하는 방법
1. DNS 서버에 같은 도메인 이름으로 ***여러 IP 주소***를 등록
2. 이후 DNS 서버가 도메인 조회에 대한 응답으로 등록한 IP 주소를 ***차례대로*** 응답 (=`라운드 로빈`)

DNS 서버에서 분배하는 방법의 문제점:
  - `health check` 문제: 고장난 웹 서버의 IP 주소를 응답할 수 있다. --> 최근 브라우저는 고장난 서버에 액세스하지 못하면 다음 IP 주소에 액세스를 시도
  - HTTP 의 `stateless` 문제: 쇼핑 사이트에서 여러 페이지에 걸쳐 폼을 작성하는 상황에서 요청의 흐름이 끊길 수 있다.

## 2 부하 분산 장치를 이용해 복수의 웹 서버로 분할된다
위의 문제점을 해결하기 위해 `부하 분산 장치` 또는 `로드 밸런서` 로 불리는 기기가 탄생.  
바로 `로드 밸런서`에 웹 서버 `도메인 이름`과 `IP 주소`를 DNS 서버에 등록하는 것.  

### 부하 분산 방법 1: 여러 페이지에 걸치지 않은 액세스일 때 (= stateless 이어도 괜찮을 때)
- CPU, 메모리 사용률에 따라 로드 밸런싱 (이 자체만으로 웹 서버에 부하를 생성)
- 시험 패킷으로 응답 시간이 가장 빠른 웹 서버에 로드 밸런싱 (이 자체만으로 웹 서버에 부하를 생성)
- 미리 설정한 웹 서버의 처리량을 바탕으로 비율을 설정하고 로드 밸런싱

### 부하 분산 방법 2: 여러 페이지에 걸친 액세스 (= stateful 이어야 할 때)
- 사실 HTTP 스펙은 정적인 문서를 다루는데 중점을 두었기 때문에 stateless 가 의도됨.
- 하지만 이전 요청과 관련된 일련의 요청들이라면 **웹 서버의 부하와 상관없이** 이전 요청을 처리한 웹 서버에 전송.
  - 프록시 때문에 `송신처 IP 주소`로만 이전 요청과 관련되있는지 확인이 불가능 
  - 따라서 HTTP 헤더를 필드에 추가해서 판단(= 쿠키)

---

# story 04  캐시 서버를 이용한 서버의 부하 분산
## 1 캐시 서버의 이용
- 캐시 서버는 `프록시` 구조로 **데이터를 캐시에 저장**하는 서버
  - 프록시: 클라이언트와 웹 서버 사이에 있다는 뜻
- 웹 서버의 데이터를 저장해놓고 웹 서버 대신 응답(=캐시)
  - 보통 웹 서버에 있는 로직을 타지 않기 때문에 응답이 빠름
- 캐시 서버에서 요청을 처리하면 웹 서버로 가는 부하를 줄일 수 있음
- 웹 서버의 데이터가 변경되면 캐시 서버에 있는 데이터를 교체해야함

## 2 캐시 서버는 갱신일로 콘텐츠를 관리한다
- DNS 서버에 캐시 서버를 등록해서 사용
  - 클라이언트 입장에선 캐시 서버가 웹 서버처럼 보임
- 캐시 서버는 클라이언트로부터 HTTP request 메시지를 받으면 `Via` 헤더에 캐시 서버를 적고 웹 서버에 전송
  - 이 때 여러 대의 웹 서버가 있다면 어떤 규칙을 만들고, 그 규칙에 따라 웹 서버를 선택해서 전송하게 해야함
  - 즉, 캐시 서버와 웹 서버가 소켓으로 연결되서 메시지를 전송하는 것

### 캐시에 데이터가 없을 때
- 웹 서버에 그대로 메시지를 전송
- 웹 서버는 응답하고, 캐시 서버는 응답한 데이터를 캐시에 저장 및 클라이언트에 응답

### 캐시에 데이터가 있을 때
- 캐시 서버는 캐시에 데이터가 있으면 `If-Modified-Since` 헤더를 추가해서 웹 서버에 전송
  - 웹 서버는 `If-Modified-Since` 헤더를 보고 `304 Not Modified` 같은 응답을 캐시 서버에 내림
- 캐시 서버는 캐시에 있는 데이터를 클라이언트에 응답(이때 클라이언트 응답에 `Via` 헤더를 붙이거나 말거나) 

## 3 프록시의 원점은 포워드 프록시이다
- 원래 프록시는 포워드 프록시 형태 뿐이었기 때문에 `포워드 프록시`라고 부르지 않았음
- ADSL, FTTH 같은 기술이 없을 당시 저속 회선 떄문에 답답해서 생긴게 포워드 프록시 --> 프록시의 캐싱 기능을 이용하기 위해 고안
- 필터링 기능: `위험한 사이트`나 `업무와 상관없는 사이트`에 대한 접근을 막을 수 있음
- 브라우저 설정이 필요함
  - 휴먼 에러 문제: 설정을 잘못하면 네트워크 오류가 생김

## 4 포워드 프록시를 개량한 리버스 프록시
- HTTP Request 메시지의 `URI` 에 적혀있는 `디렉토리명`과 `전송 대상 웹 서버(=HOST)`를 매핑해서 메시지를 전달할 수 있음
- 서버측에 설치하는 캐시 서버에서 사용

## 5 트랜스페어런트 프록시
- 패킷의 헤더(=IP 헤더)를 조사해서 액세스 대상 확인 --> 필터링 등 프록시 동작을 할 수 있다
- 따로 브라우저 설정이나 DNS 서버에 등록하지 않는다.
  - 브라우저 설정을 잘못해서 네트워크 오류가 생기는 일이 적어진다
  - 클라이언트는 트랜스페어런트 프록시의 존재를 모른다. (몰라도 된다.)
  - DNS 서버에 등록하지 않는 이유: DNS 서버에 등록해버리면 중간에 패킷 헤더를 검사하는 역할을 할 수 없게 된다.
### 동작 과정
- `브라우저 --> 웹 서버`로 패킷이 흘러가는 경로에 설치한다.
- 프록시를 통과할 때 패킷을 가로챈다.
- 가로챈 패킷을 검사해서 전송할지 버릴지 필터링할 수 있다.

--- 

# story 05 콘텐츠 배포 서비스
## 1 콘텐츠 배포 서비스를 이용한 부하 분산
### 웹 서버측에 캐시 서버를 두는 경우
- 웹 서버 부하를 억제할 수 있음
- 하지만 인터넷 트래픽을 억제하지 못함

### 클라이언트측에 캐시 서버를 두는 경우
- 인터넷 트래픽을 억제할 수 있음
- 서버 운영자가 캐시 서버를 제어할 수 없음
  - 캐시 서버의 용량을 늘리는 등의 제어를 하기가 힘듦
  - 캐시 서버가 항상 클라이언트에 있는건 아님(미국 <--> 한국 예시에서 캐시 서버가 일본에 있는 경우)

### 인터넷 주위에 캐시 서버를 두는 경우
- 인터넷 트래픽도 억제할 수 있고 캐시 서버도 제어할 수 있음
- 중요한 프로바이더 중점으로 캐시 서버를 두면 됨 (=`CDN`)
- 프로바이더와 계약해서 캐시 서버를 설치하고 이걸 서버 운영자에게 빌려주는 서비스가 생김 (=`CDS`)
  - 이런 사업자들을 CDSP 라고 함
  - 캐시 서버를 다수의 서버 운영자들이 공동으로 이용 --> 비용 절감
  - 프로바이더와의 계약은 CDSP 들이 알아서 함 --> 서버 운영자들의 노력 절감

## 2 가장 가까운 캐시 서버의 관점
CDS 를 이용한다면 클라이언트와 가장 가까운 캐시 서버에서 응답하도록 해야함.

### 클라이언트와 캐시 서버의 거리를 판단하는 방법 1
- `DNS 서버(서버측)`는 캐시 서버가 설치된 장소의 라우터들로부터 경로 정보를 모음
- 클라이언트가 `DNS 서버(서버측)`에 질의하면 DNS 서버는 모아둔 경로 정보로부터 클라이언트와 가장 까가운 캐시 서버의 IP 주소(라우터)를 알려줌
  - 거리가 정확하지 않지만 웬만큼 정확함
- 가까운 캐시 서버에 흘러온 패킷에 따라 캐시 서버가 클라이언트에 데이터를 응답함

## 3 리피터용 서버로 액세스 대상을 분배한다
### 클라이언트와 캐시 서버의 거리를 판단하는 방법 2
- 서버 운영자는 `DNS 서버(서버측)`에 리다이렉트용 서버를 등록
  - 리다이렉트용 서버엔 캐시 서버의 라우터들로부터 모은 경로 정보들이 있음
- 클라이언트가 `DNS 서버(서버측)`에 질의하면 DNS 서버는 리다이렉션 응답을 보냄(`Location 헤더`)
- 클라이언트가 다시 리다이렉트용 서버에 요청 메시지 전송하면 리다이렉트용 서버가 다시 캐시 서버로 리다이렉션 응답을 보냄(`Location 헤더`)
- 클라이언트가 다시 캐시 서버에 요청 메시지를 전송해서 캐시 서버로부터 데이터를 받음

이 방법은 3번의 TCP 접속이 일어나지만 가장 정밀도가 높음(클라이언트의 IP 주소를 확인하기 때문에)

### 클라이언트와 캐시 서버의 거리를 판단하는 방법 3
- 패킷의 왕복 시간을 통해 캐시 서버와의 거리를 계산해서 최적의 캐시 서버에 액세스하도록 스크립팅된 페이지를 응답하는 방법도 있음
- 이 방법은 클라이언트 측에서 스크립트에 따라 스스로 최적의 캐시 서버를 찾아 액세스함
  - 스스로 캐시 서버들에게 패킷을 보내고 왕복 시간을 측정하기 때문

## 4 캐시 내용의 갱신 방법에서 성능의 차이가 난다
- 캐시 서버를 이용하더라도 두 번째 이후의 액세스에도 웹 서버에 원본 데이터가 변경되었는지 확인하는 동작 떄문에 응답 시간이 느려짐.
- 이를 개션하려면 웹 서버에서 원본 데이터가 변경된 경우 `즉시` 캐시 서버에 반영해야 함
  - 웹 서버가 캐시 서버의 `캐시를 항상 최신화`하면 캐시 서버에 `최초` 액세스에도 `항상` 캐시 데이터를 이용할 수 있게 하는 것임
- 동적 페이지인 경우 변하지 않는 부분만 캐시 서버에 저장하도록 주의해야 함
